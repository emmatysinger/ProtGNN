{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "from importlib import reload\n",
    "\n",
    "# Import the desired libraries\n",
    "import txgnn\n",
    "\n",
    "# Reload the libraries\n",
    "reload(txgnn)\n",
    "\n",
    "from txgnn import TxData, TxGNN, TxEval\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Found local copy...\n",
      "Found local copy...\n",
      "Found saved processed KG... Loading...\n",
      "Splits detected... Loading splits....\n",
      "Creating DGL graph....\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "TxData_inst = TxData(data_folder_path = '/om/user/tysinger/kg/')\n",
    "TxData_inst.prepare_split(split = 'random', seed = 42, no_kg = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 8pqejm31\n",
      "Sweep URL: https://wandb.ai/eptysinger/uncategorized/sweeps/8pqejm31\n"
     ]
    }
   ],
   "source": [
    "sweep_configuration = {\n",
    "            \"method\": \"bayes\",\n",
    "            \"name\": \"sweep\",\n",
    "            \"metric\": {\"goal\": \"minimize\", \"name\": \"validation_loss\"},\n",
    "            \"parameters\": {\n",
    "                \"n_hid\": {\"values\":[64,128,256,512,1280]}, \n",
    "                \"n_inp\": {\"values\":[64,128,256,512,1280]}, \n",
    "                \"n_out\": {\"values\":[64,128,256,512,1280]}, \n",
    "                \"epochs\": {\"min\": 10, \"max\": 300},\n",
    "                \"lr\": {\"max\": 0.1, \"min\": 0.0001},\n",
    "            },\n",
    "        }\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    TxGNN_model = txgnn.TxGNN(data = TxData_inst, \n",
    "            weight_bias_track = True,\n",
    "            proj_name = 'MEng',\n",
    "            exp_name = 'Sweep',\n",
    "            device = 'cpu'\n",
    "            )\n",
    "\n",
    "    print('Initializing Model')\n",
    "    TxGNN_model.model_initialize(n_hid = wandb.config.n_hid, \n",
    "                    n_inp = wandb.config.n_inp, \n",
    "                    n_out = wandb.config.n_out, \n",
    "                    proto = False, #made this False\n",
    "                    proto_num = 3,\n",
    "                    attention = False,\n",
    "                    sim_measure = 'all_nodes_profile',\n",
    "                    bert_measure = 'disease_name',\n",
    "                    agg_measure = 'rarity',\n",
    "                    num_walks = 200,\n",
    "                    walk_mode = 'bit',\n",
    "                    path_length = 2)\n",
    "    \n",
    "    TxGNN_model.load_pretrained('/om/user/tysinger/models/pretrain_random_1')\n",
    "    print('Finetuning Model')\n",
    "    TxGNN_model.finetune(n_epoch = wandb.config.epochs, \n",
    "                learning_rate = wandb.config.lr,\n",
    "                train_print_per_n = 5,\n",
    "                valid_per_n = 50,\n",
    "                save_path = '/om/user/tysinger/models', \n",
    "                name = 'sweep')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6b88usyd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 263\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.07284665201381782\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_hid: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_inp: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_out: 256\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/weka/scratch/weka/kellislab/tysinger/TxGNN/wandb/run-20231205_165531-6b88usyd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eptysinger/uncategorized/runs/6b88usyd' target=\"_blank\">Sweep</a></strong> to <a href='https://wandb.ai/eptysinger/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/eptysinger/uncategorized/sweeps/8pqejm31' target=\"_blank\">https://wandb.ai/eptysinger/uncategorized/sweeps/8pqejm31</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eptysinger/uncategorized' target=\"_blank\">https://wandb.ai/eptysinger/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eptysinger/uncategorized/sweeps/8pqejm31' target=\"_blank\">https://wandb.ai/eptysinger/uncategorized/sweeps/8pqejm31</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eptysinger/uncategorized/runs/6b88usyd' target=\"_blank\">https://wandb.ai/eptysinger/uncategorized/runs/6b88usyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Model\n",
      "Finetuning Model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sweep</strong> at: <a href='https://wandb.ai/eptysinger/uncategorized/runs/6b88usyd' target=\"_blank\">https://wandb.ai/eptysinger/uncategorized/runs/6b88usyd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231205_165531-6b88usyd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 6b88usyd errored: DGLError('[16:59:43] /opt/dgl/src/array/cpu/./spmm_blocking_libxsmm.h:267: Failed to generate libxsmm kernel for the SpMM operation.To disable libxsmm, use dgl.use_libxsmm(false).\\nStack trace:\\n  [bt] (0) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x2acf8b59cbff]\\n  [bt] (1) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::cpu::SpMMRedopCsrOpt<long, float, dgl::aten::cpu::op::CopyLhs<float>, dgl::aten::cpu::op::Add<float> >(dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x3d4) [0x2acf8b7e9e54]\\n  [bt] (2) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::cpu::SpMMSumCsrLibxsmm<long, float, dgl::aten::cpu::op::CopyLhs<float> >(dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x73) [0x2acf8b7e9f03]\\n  [bt] (3) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::cpu::SpMMSumCsr<long, float, dgl::aten::cpu::op::CopyLhs<float> >(dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x1a2) [0x2acf8b805732]\\n  [bt] (4) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::SpMMCsr<1, long, 32>(std::string const&, std::string const&, dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, std::vector<dgl::runtime::NDArray, std::allocator<dgl::runtime::NDArray> >)+0xcd3) [0x2acf8b81bb73]\\n  [bt] (5) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::SpMM(std::string const&, std::string const&, std::shared_ptr<dgl::BaseHeteroGraph>, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, std::vector<dgl::runtime::NDArray, std::allocator<dgl::runtime::NDArray> >)+0x244e) [0x2acf8b85040e]\\n  [bt] (6) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(+0x66cd50) [0x2acf8b86fd50]\\n  [bt] (7) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(+0x66d361) [0x2acf8b870361]\\n  [bt] (8) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(DGLFuncCall+0x48) [0x2acf8b8c3138]\\n\\n')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 6b88usyd errored: DGLError('[16:59:43] /opt/dgl/src/array/cpu/./spmm_blocking_libxsmm.h:267: Failed to generate libxsmm kernel for the SpMM operation.To disable libxsmm, use dgl.use_libxsmm(false).\\nStack trace:\\n  [bt] (0) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x2acf8b59cbff]\\n  [bt] (1) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::cpu::SpMMRedopCsrOpt<long, float, dgl::aten::cpu::op::CopyLhs<float>, dgl::aten::cpu::op::Add<float> >(dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x3d4) [0x2acf8b7e9e54]\\n  [bt] (2) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::cpu::SpMMSumCsrLibxsmm<long, float, dgl::aten::cpu::op::CopyLhs<float> >(dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x73) [0x2acf8b7e9f03]\\n  [bt] (3) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::cpu::SpMMSumCsr<long, float, dgl::aten::cpu::op::CopyLhs<float> >(dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x1a2) [0x2acf8b805732]\\n  [bt] (4) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::SpMMCsr<1, long, 32>(std::string const&, std::string const&, dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, std::vector<dgl::runtime::NDArray, std::allocator<dgl::runtime::NDArray> >)+0xcd3) [0x2acf8b81bb73]\\n  [bt] (5) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::SpMM(std::string const&, std::string const&, std::shared_ptr<dgl::BaseHeteroGraph>, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, std::vector<dgl::runtime::NDArray, std::allocator<dgl::runtime::NDArray> >)+0x244e) [0x2acf8b85040e]\\n  [bt] (6) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(+0x66cd50) [0x2acf8b86fd50]\\n  [bt] (7) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(+0x66d361) [0x2acf8b870361]\\n  [bt] (8) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(DGLFuncCall+0x48) [0x2acf8b8c3138]\\n\\n')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6wni9e5j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 169\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.04954627927138229\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_hid: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_inp: 1280\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_out: 128\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Cannot find valid git repo associated with this directory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/weka/scratch/weka/kellislab/tysinger/TxGNN/wandb/run-20231205_170028-6wni9e5j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eptysinger/uncategorized/runs/6wni9e5j' target=\"_blank\">Sweep</a></strong> to <a href='https://wandb.ai/eptysinger/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/eptysinger/uncategorized/sweeps/8pqejm31' target=\"_blank\">https://wandb.ai/eptysinger/uncategorized/sweeps/8pqejm31</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eptysinger/uncategorized' target=\"_blank\">https://wandb.ai/eptysinger/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eptysinger/uncategorized/sweeps/8pqejm31' target=\"_blank\">https://wandb.ai/eptysinger/uncategorized/sweeps/8pqejm31</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eptysinger/uncategorized/runs/6wni9e5j' target=\"_blank\">https://wandb.ai/eptysinger/uncategorized/runs/6wni9e5j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Model\n",
      "Finetuning Model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Sweep</strong> at: <a href='https://wandb.ai/eptysinger/uncategorized/runs/6wni9e5j' target=\"_blank\">https://wandb.ai/eptysinger/uncategorized/runs/6wni9e5j</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231205_170028-6wni9e5j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meptysinger\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/weka/scratch/weka/kellislab/tysinger/TxGNN/wandb/run-20231205_120427-om28t0x2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eptysinger/MEng/runs/om28t0x2' target=\"_blank\">Test</a></strong> to <a href='https://wandb.ai/eptysinger/MEng' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eptysinger/MEng' target=\"_blank\">https://wandb.ai/eptysinger/MEng</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eptysinger/MEng/runs/om28t0x2' target=\"_blank\">https://wandb.ai/eptysinger/MEng/runs/om28t0x2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "TxGNN_model = txgnn.TxGNN(data = TxData_inst, \n",
    "            weight_bias_track = True,\n",
    "            proj_name = 'MEng',\n",
    "            exp_name = 'Test',\n",
    "            device = 'cpu'\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "TxGNN_model.model_initialize(n_hid = 1280, \n",
    "                    n_inp = 1280, \n",
    "                    n_out = 1280, \n",
    "                    proto = False, #made this False\n",
    "                    proto_num = 3,\n",
    "                    attention = False,\n",
    "                    sim_measure = 'all_nodes_profile',\n",
    "                    bert_measure = 'disease_name',\n",
    "                    agg_measure = 'rarity',\n",
    "                    num_walks = 200,\n",
    "                    walk_mode = 'bit',\n",
    "                    path_length = 2)\n",
    "\"\"\"\n",
    "\n",
    "# to load a pretrained model: \n",
    "TxGNN_model.load_pretrained('/om/user/tysinger/models/random_finetuned150')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating minibatch pretraining dataloader...\n",
      "Start pre-training with #param: 1015000\n"
     ]
    },
    {
     "ename": "DGLError",
     "evalue": "[22:33:24] /opt/dgl/src/array/cpu/./spmm_blocking_libxsmm.h:267: Failed to generate libxsmm kernel for the SpMM operation.To disable libxsmm, use dgl.use_libxsmm(false).\nStack trace:\n  [bt] (0) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x2b9a0fd37bff]\n  [bt] (1) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::cpu::SpMMRedopCsrOpt<long, float, dgl::aten::cpu::op::CopyLhs<float>, dgl::aten::cpu::op::Add<float> >(dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x3d4) [0x2b9a0ff84e54]\n  [bt] (2) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::cpu::SpMMSumCsrLibxsmm<long, float, dgl::aten::cpu::op::CopyLhs<float> >(dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x73) [0x2b9a0ff84f03]\n  [bt] (3) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::cpu::SpMMSumCsr<long, float, dgl::aten::cpu::op::CopyLhs<float> >(dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x1a2) [0x2b9a0ffa0732]\n  [bt] (4) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::SpMMCsr<1, long, 32>(std::string const&, std::string const&, dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, std::vector<dgl::runtime::NDArray, std::allocator<dgl::runtime::NDArray> >)+0xcd3) [0x2b9a0ffb6b73]\n  [bt] (5) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::SpMM(std::string const&, std::string const&, std::shared_ptr<dgl::BaseHeteroGraph>, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, std::vector<dgl::runtime::NDArray, std::allocator<dgl::runtime::NDArray> >)+0x244e) [0x2b9a0ffeb40e]\n  [bt] (6) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(+0x66cd50) [0x2b9a1000ad50]\n  [bt] (7) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(+0x66d361) [0x2b9a1000b361]\n  [bt] (8) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(DGLFuncCall+0x48) [0x2b9a1005e138]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/om/user/tysinger/TxGNN/TxGNN_Demo.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/tysinger/TxGNN/TxGNN_Demo.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## here we did not run this, since the output is too long to fit into the notebook\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/tysinger/TxGNN/TxGNN_Demo.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m TxGNN_model\u001b[39m.\u001b[39;49mpretrain(n_epoch \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/tysinger/TxGNN/TxGNN_Demo.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                learning_rate \u001b[39m=\u001b[39;49m \u001b[39m1e-3\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/tysinger/TxGNN/TxGNN_Demo.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m                batch_size \u001b[39m=\u001b[39;49m \u001b[39m1024\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/tysinger/TxGNN/TxGNN_Demo.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m                train_print_per_n \u001b[39m=\u001b[39;49m \u001b[39m20\u001b[39;49m)\n",
      "File \u001b[0;32m/weka/scratch/weka/kellislab/tysinger/TxGNN/txgnn/TxGNN.py:157\u001b[0m, in \u001b[0;36mTxGNN.pretrain\u001b[0;34m(self, n_epoch, learning_rate, batch_size, train_print_per_n, sweep_wandb)\u001b[0m\n\u001b[1;32m    155\u001b[0m pos_g \u001b[39m=\u001b[39m pos_g\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    156\u001b[0m neg_g \u001b[39m=\u001b[39m neg_g\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 157\u001b[0m pred_score_pos, pred_score_neg, pos_score, neg_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mforward_minibatch(pos_g, neg_g, blocks, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mG, mode \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, pretrain_mode \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    159\u001b[0m scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((pos_score, neg_score))\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,)\n\u001b[1;32m    160\u001b[0m labels \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(pos_score) \u001b[39m+\u001b[39m [\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(neg_score)\n",
      "File \u001b[0;32m/weka/scratch/weka/kellislab/tysinger/TxGNN/txgnn/model.py:476\u001b[0m, in \u001b[0;36mHeteroRGCN.forward_minibatch\u001b[0;34m(self, pos_G, neg_G, blocks, G, mode, pretrain_mode)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_minibatch\u001b[39m(\u001b[39mself\u001b[39m, pos_G, neg_G, blocks, G, mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, pretrain_mode \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    475\u001b[0m     input_dict \u001b[39m=\u001b[39m blocks[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msrcdata[\u001b[39m'\u001b[39m\u001b[39minp\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 476\u001b[0m     h_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer1(blocks[\u001b[39m0\u001b[39;49m], input_dict)\n\u001b[1;32m    477\u001b[0m     h_dict \u001b[39m=\u001b[39m {k : F\u001b[39m.\u001b[39mleaky_relu(h) \u001b[39mfor\u001b[39;00m k, h \u001b[39min\u001b[39;00m h_dict\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    478\u001b[0m     h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(blocks[\u001b[39m1\u001b[39m], h_dict)\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/weka/scratch/weka/kellislab/tysinger/TxGNN/txgnn/model.py:380\u001b[0m, in \u001b[0;36mHeteroRGCNLayer.forward\u001b[0;34m(self, G, feat_dict)\u001b[0m\n\u001b[1;32m    378\u001b[0m     G\u001b[39m.\u001b[39mnodes[srctype]\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39mWh_\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m etype] \u001b[39m=\u001b[39m Wh\n\u001b[1;32m    379\u001b[0m     funcs[etype] \u001b[39m=\u001b[39m (fn\u001b[39m.\u001b[39mcopy_u(\u001b[39m'\u001b[39m\u001b[39mWh_\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m etype, \u001b[39m'\u001b[39m\u001b[39mm\u001b[39m\u001b[39m'\u001b[39m), fn\u001b[39m.\u001b[39mmean(\u001b[39m'\u001b[39m\u001b[39mm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m--> 380\u001b[0m G\u001b[39m.\u001b[39;49mmulti_update_all(funcs, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    382\u001b[0m \u001b[39mreturn\u001b[39;00m {ntype : G\u001b[39m.\u001b[39mdstdata[\u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m][ntype] \u001b[39mfor\u001b[39;00m ntype \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(G\u001b[39m.\u001b[39mdstdata[\u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mkeys())}\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/heterograph.py:5023\u001b[0m, in \u001b[0;36mDGLHeteroGraph.multi_update_all\u001b[0;34m(self, etype_dict, cross_reducer, apply_node_func)\u001b[0m\n\u001b[1;32m   5021\u001b[0m     mfunc, rfunc, afunc \u001b[39m=\u001b[39m args\n\u001b[1;32m   5022\u001b[0m     g \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m etype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m[etype]\n\u001b[0;32m-> 5023\u001b[0m     all_out[dtid]\u001b[39m.\u001b[39mappend(core\u001b[39m.\u001b[39;49mmessage_passing(g, mfunc, rfunc, afunc))\n\u001b[1;32m   5024\u001b[0m     merge_order[dtid]\u001b[39m.\u001b[39mappend(etid)  \u001b[39m# use edge type id as merge order hint\u001b[39;00m\n\u001b[1;32m   5025\u001b[0m \u001b[39mfor\u001b[39;00m dtid, frames \u001b[39min\u001b[39;00m all_out\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   5026\u001b[0m     \u001b[39m# merge by cross_reducer\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/core.py:357\u001b[0m, in \u001b[0;36mmessage_passing\u001b[0;34m(g, mfunc, rfunc, afunc)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Invoke message passing computation on the whole graph.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \n\u001b[1;32m    338\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39m    Results from the message passing computation.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m (is_builtin(mfunc) \u001b[39mand\u001b[39;00m is_builtin(rfunc) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    355\u001b[0m         \u001b[39mgetattr\u001b[39m(ops, \u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(mfunc\u001b[39m.\u001b[39mname, rfunc\u001b[39m.\u001b[39mname), \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    356\u001b[0m     \u001b[39m# invoke fused message passing\u001b[39;00m\n\u001b[0;32m--> 357\u001b[0m     ndata \u001b[39m=\u001b[39m invoke_gspmm(g, mfunc, rfunc)\n\u001b[1;32m    358\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[39m# invoke message passing in two separate steps\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     \u001b[39m# message phase\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[39mif\u001b[39;00m is_builtin(mfunc):\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/core.py:332\u001b[0m, in \u001b[0;36minvoke_gspmm\u001b[0;34m(graph, mfunc, rfunc, srcdata, dstdata, edata)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[39melse\u001b[39;00m: \u001b[39m# \"copy_e\"\u001b[39;00m\n\u001b[1;32m    331\u001b[0m             x \u001b[39m=\u001b[39m data_dict_to_list(graph, x, mfunc, \u001b[39m'\u001b[39m\u001b[39me\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 332\u001b[0m     z \u001b[39m=\u001b[39m op(graph, x)\n\u001b[1;32m    333\u001b[0m \u001b[39mreturn\u001b[39;00m {rfunc\u001b[39m.\u001b[39mout_field : z}\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/ops/spmm.py:189\u001b[0m, in \u001b[0;36m_gen_copy_reduce_func.<locals>.func\u001b[0;34m(g, x)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m(g, x):\n\u001b[1;32m    188\u001b[0m     \u001b[39mif\u001b[39;00m binary_op \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcopy_u\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 189\u001b[0m         \u001b[39mreturn\u001b[39;00m gspmm(g, \u001b[39m'\u001b[39;49m\u001b[39mcopy_lhs\u001b[39;49m\u001b[39m'\u001b[39;49m, reduce_op, x, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    190\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m         \u001b[39mreturn\u001b[39;00m gspmm(g, \u001b[39m'\u001b[39m\u001b[39mcopy_rhs\u001b[39m\u001b[39m'\u001b[39m, reduce_op, \u001b[39mNone\u001b[39;00m, x)\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/ops/spmm.py:75\u001b[0m, in \u001b[0;36mgspmm\u001b[0;34m(g, op, reduce_op, lhs_data, rhs_data)\u001b[0m\n\u001b[1;32m     73\u001b[0m         lhs_data, rhs_data \u001b[39m=\u001b[39m reshape_lhs_rhs(lhs_data, rhs_data)\n\u001b[1;32m     74\u001b[0m     \u001b[39m# With max and min reducers infinity will be returned for zero degree nodes\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     ret \u001b[39m=\u001b[39m gspmm_internal(g\u001b[39m.\u001b[39;49m_graph, op,\n\u001b[1;32m     76\u001b[0m                          \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39mif\u001b[39;49;00m reduce_op \u001b[39m==\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39melse\u001b[39;49;00m reduce_op,\n\u001b[1;32m     77\u001b[0m                          lhs_data, rhs_data)\n\u001b[1;32m     78\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     \u001b[39m# lhs_data or rhs_data is None only in unary functions like ``copy-u`` or ``copy_e``\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     lhs_data \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m g\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39mnumber_of_ntypes() \u001b[39mif\u001b[39;00m lhs_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m lhs_data\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/backend/pytorch/sparse.py:724\u001b[0m, in \u001b[0;36mgspmm\u001b[0;34m(gidx, op, reduce_op, lhs_data, rhs_data)\u001b[0m\n\u001b[1;32m    722\u001b[0m     op \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmul\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    723\u001b[0m     rhs_data \u001b[39m=\u001b[39m \u001b[39m1.\u001b[39m \u001b[39m/\u001b[39m rhs_data\n\u001b[0;32m--> 724\u001b[0m \u001b[39mreturn\u001b[39;00m GSpMM\u001b[39m.\u001b[39;49mapply(gidx, op, reduce_op, lhs_data, rhs_data)\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/torch/cuda/amp/autocast_mode.py:105\u001b[0m, in \u001b[0;36mcustom_fwd.<locals>.decorate_fwd\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[39mreturn\u001b[39;00m fwd(\u001b[39m*\u001b[39m_cast(args, cast_inputs), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_cast(kwargs, cast_inputs))\n\u001b[1;32m    104\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[39mreturn\u001b[39;00m fwd(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/backend/pytorch/sparse.py:106\u001b[0m, in \u001b[0;36mGSpMM.forward\u001b[0;34m(ctx, gidx, op, reduce_op, X, Y)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[39m@custom_fwd\u001b[39m(cast_inputs\u001b[39m=\u001b[39mth\u001b[39m.\u001b[39mfloat16)\n\u001b[1;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(ctx, gidx, op, reduce_op, X, Y):\n\u001b[0;32m--> 106\u001b[0m     out, (argX, argY) \u001b[39m=\u001b[39m _gspmm(gidx, op, reduce_op, X, Y)\n\u001b[1;32m    107\u001b[0m     reduce_last \u001b[39m=\u001b[39m _need_reduce_last_dim(X, Y)\n\u001b[1;32m    108\u001b[0m     X_shape \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/sparse.py:228\u001b[0m, in \u001b[0;36m_gspmm\u001b[0;34m(gidx, op, reduce_op, u, e)\u001b[0m\n\u001b[1;32m    226\u001b[0m arg_e_nd \u001b[39m=\u001b[39m to_dgl_nd_for_write(arg_e)\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m gidx\u001b[39m.\u001b[39mnumber_of_edges(\u001b[39m0\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 228\u001b[0m     _CAPI_DGLKernelSpMM(gidx, op, reduce_op,\n\u001b[1;32m    229\u001b[0m                         to_dgl_nd(u \u001b[39mif\u001b[39;49;00m use_u \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    230\u001b[0m                         to_dgl_nd(e \u001b[39mif\u001b[39;49;00m use_e \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    231\u001b[0m                         to_dgl_nd_for_write(v),\n\u001b[1;32m    232\u001b[0m                         arg_u_nd,\n\u001b[1;32m    233\u001b[0m                         arg_e_nd)\n\u001b[1;32m    234\u001b[0m \u001b[39m# NOTE(zihao): actually we can avoid the following step, because arg_*_nd\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[39m# refers to the data that stores arg_*. After we call _CAPI_DGLKernelSpMM,\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39m# arg_* should have already been changed. But we found this doesn't work\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[39m# The workaround is proposed by Jinjing, and we still need to investigate\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39m# where the problem is.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m arg_u \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m arg_u \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m F\u001b[39m.\u001b[39mzerocopy_from_dgl_ndarray(arg_u_nd)\n",
      "File \u001b[0;32mdgl/_ffi/_cython/./function.pxi:293\u001b[0m, in \u001b[0;36mdgl._ffi._cy3.core.FunctionBase.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mdgl/_ffi/_cython/./function.pxi:239\u001b[0m, in \u001b[0;36mdgl._ffi._cy3.core.FuncCall\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDGLError\u001b[0m: [22:33:24] /opt/dgl/src/array/cpu/./spmm_blocking_libxsmm.h:267: Failed to generate libxsmm kernel for the SpMM operation.To disable libxsmm, use dgl.use_libxsmm(false).\nStack trace:\n  [bt] (0) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x2b9a0fd37bff]\n  [bt] (1) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::cpu::SpMMRedopCsrOpt<long, float, dgl::aten::cpu::op::CopyLhs<float>, dgl::aten::cpu::op::Add<float> >(dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x3d4) [0x2b9a0ff84e54]\n  [bt] (2) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::cpu::SpMMSumCsrLibxsmm<long, float, dgl::aten::cpu::op::CopyLhs<float> >(dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x73) [0x2b9a0ff84f03]\n  [bt] (3) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::cpu::SpMMSumCsr<long, float, dgl::aten::cpu::op::CopyLhs<float> >(dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x1a2) [0x2b9a0ffa0732]\n  [bt] (4) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::SpMMCsr<1, long, 32>(std::string const&, std::string const&, dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, std::vector<dgl::runtime::NDArray, std::allocator<dgl::runtime::NDArray> >)+0xcd3) [0x2b9a0ffb6b73]\n  [bt] (5) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::SpMM(std::string const&, std::string const&, std::shared_ptr<dgl::BaseHeteroGraph>, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, std::vector<dgl::runtime::NDArray, std::allocator<dgl::runtime::NDArray> >)+0x244e) [0x2b9a0ffeb40e]\n  [bt] (6) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(+0x66cd50) [0x2b9a1000ad50]\n  [bt] (7) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(+0x66d361) [0x2b9a1000b361]\n  [bt] (8) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(DGLFuncCall+0x48) [0x2b9a1005e138]\n\n"
     ]
    }
   ],
   "source": [
    "## here we did not run this, since the output is too long to fit into the notebook\n",
    "TxGNN_model.pretrain(n_epoch = 1, \n",
    "               learning_rate = 1e-3,\n",
    "               batch_size = 1024, \n",
    "               train_print_per_n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "DGLError",
     "evalue": "[12:08:36] /opt/dgl/src/array/cpu/./spmm_blocking_libxsmm.h:267: Failed to generate libxsmm kernel for the SpMM operation.To disable libxsmm, use dgl.use_libxsmm(false).\nStack trace:\n  [bt] (0) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x2b048e361bff]\n  [bt] (1) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::cpu::SpMMRedopCsrOpt<long, float, dgl::aten::cpu::op::CopyLhs<float>, dgl::aten::cpu::op::Add<float> >(dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x3d4) [0x2b048e5aee54]\n  [bt] (2) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::cpu::SpMMSumCsrLibxsmm<long, float, dgl::aten::cpu::op::CopyLhs<float> >(dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x73) [0x2b048e5aef03]\n  [bt] (3) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::cpu::SpMMSumCsr<long, float, dgl::aten::cpu::op::CopyLhs<float> >(dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x1a2) [0x2b048e5ca732]\n  [bt] (4) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::SpMMCsr<1, long, 32>(std::string const&, std::string const&, dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, std::vector<dgl::runtime::NDArray, std::allocator<dgl::runtime::NDArray> >)+0xcd3) [0x2b048e5e0b73]\n  [bt] (5) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::SpMM(std::string const&, std::string const&, std::shared_ptr<dgl::BaseHeteroGraph>, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, std::vector<dgl::runtime::NDArray, std::allocator<dgl::runtime::NDArray> >)+0x244e) [0x2b048e61540e]\n  [bt] (6) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(+0x66cd50) [0x2b048e634d50]\n  [bt] (7) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(+0x66d361) [0x2b048e635361]\n  [bt] (8) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(DGLFuncCall+0x48) [0x2b048e688138]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/om/user/tysinger/TxGNN/TxGNN_Demo.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/tysinger/TxGNN/TxGNN_Demo.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## here as a demo, the n_epoch is set to 30. Change it to n_epoch = 500 when you use it\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/tysinger/TxGNN/TxGNN_Demo.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m TxGNN_model\u001b[39m.\u001b[39;49mfinetune(n_epoch \u001b[39m=\u001b[39;49m \u001b[39m15\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/tysinger/TxGNN/TxGNN_Demo.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                learning_rate \u001b[39m=\u001b[39;49m \u001b[39m5e-4\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/tysinger/TxGNN/TxGNN_Demo.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m                train_print_per_n \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/tysinger/TxGNN/TxGNN_Demo.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m                valid_per_n \u001b[39m=\u001b[39;49m \u001b[39m50\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/tysinger/TxGNN/TxGNN_Demo.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m                save_path \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m/om/user/tysinger/models\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/tysinger/TxGNN/TxGNN_Demo.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m                 name \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mrandom_finetune\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/weka/scratch/weka/kellislab/tysinger/TxGNN/txgnn/TxGNN.py:232\u001b[0m, in \u001b[0;36mTxGNN.finetune\u001b[0;34m(self, save_path, name, n_epoch, learning_rate, train_print_per_n, valid_per_n, sweep_wandb, save_name, save_per_n, b)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epoch):\n\u001b[1;32m    231\u001b[0m     negative_graph \u001b[39m=\u001b[39m neg_sampler(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mG)\n\u001b[0;32m--> 232\u001b[0m     pred_score_pos, pred_score_neg, pos_score, neg_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mG, negative_graph, pretrain_mode \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m, mode \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    234\u001b[0m     pos_score \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([pred_score_pos[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpmf_etypes]) \u001b[39m#CHANGED\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     neg_score \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([pred_score_neg[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpmf_etypes]) \u001b[39m#CHANGED\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/weka/scratch/weka/kellislab/tysinger/TxGNN/txgnn/model.py:481\u001b[0m, in \u001b[0;36mHeteroRGCN.forward\u001b[0;34m(self, G, neg_G, eval_pos_G, return_h, return_att, mode, pretrain_mode)\u001b[0m\n\u001b[1;32m    479\u001b[0m     h, a_dict_l2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(G, h_dict, return_att)\n\u001b[1;32m    480\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 481\u001b[0m     h_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer1(G, input_dict)\n\u001b[1;32m    482\u001b[0m     h_dict \u001b[39m=\u001b[39m {k : F\u001b[39m.\u001b[39mleaky_relu(h) \u001b[39mfor\u001b[39;00m k, h \u001b[39min\u001b[39;00m h_dict\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    483\u001b[0m     h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(G, h_dict)\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/weka/scratch/weka/kellislab/tysinger/TxGNN/txgnn/model.py:367\u001b[0m, in \u001b[0;36mHeteroRGCNLayer.forward\u001b[0;34m(self, G, feat_dict)\u001b[0m\n\u001b[1;32m    365\u001b[0m     G\u001b[39m.\u001b[39mnodes[srctype]\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39mWh_\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m etype] \u001b[39m=\u001b[39m Wh\n\u001b[1;32m    366\u001b[0m     funcs[etype] \u001b[39m=\u001b[39m (fn\u001b[39m.\u001b[39mcopy_u(\u001b[39m'\u001b[39m\u001b[39mWh_\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m etype, \u001b[39m'\u001b[39m\u001b[39mm\u001b[39m\u001b[39m'\u001b[39m), fn\u001b[39m.\u001b[39mmean(\u001b[39m'\u001b[39m\u001b[39mm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m--> 367\u001b[0m G\u001b[39m.\u001b[39;49mmulti_update_all(funcs, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    369\u001b[0m \u001b[39mreturn\u001b[39;00m {ntype : G\u001b[39m.\u001b[39mdstdata[\u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m][ntype] \u001b[39mfor\u001b[39;00m ntype \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(G\u001b[39m.\u001b[39mdstdata[\u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mkeys())}\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/heterograph.py:5023\u001b[0m, in \u001b[0;36mDGLHeteroGraph.multi_update_all\u001b[0;34m(self, etype_dict, cross_reducer, apply_node_func)\u001b[0m\n\u001b[1;32m   5021\u001b[0m     mfunc, rfunc, afunc \u001b[39m=\u001b[39m args\n\u001b[1;32m   5022\u001b[0m     g \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m etype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m[etype]\n\u001b[0;32m-> 5023\u001b[0m     all_out[dtid]\u001b[39m.\u001b[39mappend(core\u001b[39m.\u001b[39;49mmessage_passing(g, mfunc, rfunc, afunc))\n\u001b[1;32m   5024\u001b[0m     merge_order[dtid]\u001b[39m.\u001b[39mappend(etid)  \u001b[39m# use edge type id as merge order hint\u001b[39;00m\n\u001b[1;32m   5025\u001b[0m \u001b[39mfor\u001b[39;00m dtid, frames \u001b[39min\u001b[39;00m all_out\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   5026\u001b[0m     \u001b[39m# merge by cross_reducer\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/core.py:357\u001b[0m, in \u001b[0;36mmessage_passing\u001b[0;34m(g, mfunc, rfunc, afunc)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Invoke message passing computation on the whole graph.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \n\u001b[1;32m    338\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39m    Results from the message passing computation.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m (is_builtin(mfunc) \u001b[39mand\u001b[39;00m is_builtin(rfunc) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    355\u001b[0m         \u001b[39mgetattr\u001b[39m(ops, \u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(mfunc\u001b[39m.\u001b[39mname, rfunc\u001b[39m.\u001b[39mname), \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    356\u001b[0m     \u001b[39m# invoke fused message passing\u001b[39;00m\n\u001b[0;32m--> 357\u001b[0m     ndata \u001b[39m=\u001b[39m invoke_gspmm(g, mfunc, rfunc)\n\u001b[1;32m    358\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[39m# invoke message passing in two separate steps\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     \u001b[39m# message phase\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[39mif\u001b[39;00m is_builtin(mfunc):\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/core.py:332\u001b[0m, in \u001b[0;36minvoke_gspmm\u001b[0;34m(graph, mfunc, rfunc, srcdata, dstdata, edata)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[39melse\u001b[39;00m: \u001b[39m# \"copy_e\"\u001b[39;00m\n\u001b[1;32m    331\u001b[0m             x \u001b[39m=\u001b[39m data_dict_to_list(graph, x, mfunc, \u001b[39m'\u001b[39m\u001b[39me\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 332\u001b[0m     z \u001b[39m=\u001b[39m op(graph, x)\n\u001b[1;32m    333\u001b[0m \u001b[39mreturn\u001b[39;00m {rfunc\u001b[39m.\u001b[39mout_field : z}\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/ops/spmm.py:189\u001b[0m, in \u001b[0;36m_gen_copy_reduce_func.<locals>.func\u001b[0;34m(g, x)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m(g, x):\n\u001b[1;32m    188\u001b[0m     \u001b[39mif\u001b[39;00m binary_op \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcopy_u\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 189\u001b[0m         \u001b[39mreturn\u001b[39;00m gspmm(g, \u001b[39m'\u001b[39;49m\u001b[39mcopy_lhs\u001b[39;49m\u001b[39m'\u001b[39;49m, reduce_op, x, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    190\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m         \u001b[39mreturn\u001b[39;00m gspmm(g, \u001b[39m'\u001b[39m\u001b[39mcopy_rhs\u001b[39m\u001b[39m'\u001b[39m, reduce_op, \u001b[39mNone\u001b[39;00m, x)\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/ops/spmm.py:75\u001b[0m, in \u001b[0;36mgspmm\u001b[0;34m(g, op, reduce_op, lhs_data, rhs_data)\u001b[0m\n\u001b[1;32m     73\u001b[0m         lhs_data, rhs_data \u001b[39m=\u001b[39m reshape_lhs_rhs(lhs_data, rhs_data)\n\u001b[1;32m     74\u001b[0m     \u001b[39m# With max and min reducers infinity will be returned for zero degree nodes\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     ret \u001b[39m=\u001b[39m gspmm_internal(g\u001b[39m.\u001b[39;49m_graph, op,\n\u001b[1;32m     76\u001b[0m                          \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39mif\u001b[39;49;00m reduce_op \u001b[39m==\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39melse\u001b[39;49;00m reduce_op,\n\u001b[1;32m     77\u001b[0m                          lhs_data, rhs_data)\n\u001b[1;32m     78\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     \u001b[39m# lhs_data or rhs_data is None only in unary functions like ``copy-u`` or ``copy_e``\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     lhs_data \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m g\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39mnumber_of_ntypes() \u001b[39mif\u001b[39;00m lhs_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m lhs_data\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/backend/pytorch/sparse.py:724\u001b[0m, in \u001b[0;36mgspmm\u001b[0;34m(gidx, op, reduce_op, lhs_data, rhs_data)\u001b[0m\n\u001b[1;32m    722\u001b[0m     op \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmul\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    723\u001b[0m     rhs_data \u001b[39m=\u001b[39m \u001b[39m1.\u001b[39m \u001b[39m/\u001b[39m rhs_data\n\u001b[0;32m--> 724\u001b[0m \u001b[39mreturn\u001b[39;00m GSpMM\u001b[39m.\u001b[39;49mapply(gidx, op, reduce_op, lhs_data, rhs_data)\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/torch/cuda/amp/autocast_mode.py:105\u001b[0m, in \u001b[0;36mcustom_fwd.<locals>.decorate_fwd\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[39mreturn\u001b[39;00m fwd(\u001b[39m*\u001b[39m_cast(args, cast_inputs), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_cast(kwargs, cast_inputs))\n\u001b[1;32m    104\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[39mreturn\u001b[39;00m fwd(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/backend/pytorch/sparse.py:106\u001b[0m, in \u001b[0;36mGSpMM.forward\u001b[0;34m(ctx, gidx, op, reduce_op, X, Y)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[39m@custom_fwd\u001b[39m(cast_inputs\u001b[39m=\u001b[39mth\u001b[39m.\u001b[39mfloat16)\n\u001b[1;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(ctx, gidx, op, reduce_op, X, Y):\n\u001b[0;32m--> 106\u001b[0m     out, (argX, argY) \u001b[39m=\u001b[39m _gspmm(gidx, op, reduce_op, X, Y)\n\u001b[1;32m    107\u001b[0m     reduce_last \u001b[39m=\u001b[39m _need_reduce_last_dim(X, Y)\n\u001b[1;32m    108\u001b[0m     X_shape \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/sparse.py:228\u001b[0m, in \u001b[0;36m_gspmm\u001b[0;34m(gidx, op, reduce_op, u, e)\u001b[0m\n\u001b[1;32m    226\u001b[0m arg_e_nd \u001b[39m=\u001b[39m to_dgl_nd_for_write(arg_e)\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m gidx\u001b[39m.\u001b[39mnumber_of_edges(\u001b[39m0\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 228\u001b[0m     _CAPI_DGLKernelSpMM(gidx, op, reduce_op,\n\u001b[1;32m    229\u001b[0m                         to_dgl_nd(u \u001b[39mif\u001b[39;49;00m use_u \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    230\u001b[0m                         to_dgl_nd(e \u001b[39mif\u001b[39;49;00m use_e \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    231\u001b[0m                         to_dgl_nd_for_write(v),\n\u001b[1;32m    232\u001b[0m                         arg_u_nd,\n\u001b[1;32m    233\u001b[0m                         arg_e_nd)\n\u001b[1;32m    234\u001b[0m \u001b[39m# NOTE(zihao): actually we can avoid the following step, because arg_*_nd\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[39m# refers to the data that stores arg_*. After we call _CAPI_DGLKernelSpMM,\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39m# arg_* should have already been changed. But we found this doesn't work\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[39m# The workaround is proposed by Jinjing, and we still need to investigate\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39m# where the problem is.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m arg_u \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m arg_u \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m F\u001b[39m.\u001b[39mzerocopy_from_dgl_ndarray(arg_u_nd)\n",
      "File \u001b[0;32mdgl/_ffi/_cython/./function.pxi:293\u001b[0m, in \u001b[0;36mdgl._ffi._cy3.core.FunctionBase.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mdgl/_ffi/_cython/./function.pxi:239\u001b[0m, in \u001b[0;36mdgl._ffi._cy3.core.FuncCall\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDGLError\u001b[0m: [12:08:36] /opt/dgl/src/array/cpu/./spmm_blocking_libxsmm.h:267: Failed to generate libxsmm kernel for the SpMM operation.To disable libxsmm, use dgl.use_libxsmm(false).\nStack trace:\n  [bt] (0) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x2b048e361bff]\n  [bt] (1) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::cpu::SpMMRedopCsrOpt<long, float, dgl::aten::cpu::op::CopyLhs<float>, dgl::aten::cpu::op::Add<float> >(dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x3d4) [0x2b048e5aee54]\n  [bt] (2) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::cpu::SpMMSumCsrLibxsmm<long, float, dgl::aten::cpu::op::CopyLhs<float> >(dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x73) [0x2b048e5aef03]\n  [bt] (3) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::cpu::SpMMSumCsr<long, float, dgl::aten::cpu::op::CopyLhs<float> >(dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x1a2) [0x2b048e5ca732]\n  [bt] (4) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(void dgl::aten::SpMMCsr<1, long, 32>(std::string const&, std::string const&, dgl::BcastOff const&, dgl::aten::CSRMatrix const&, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, std::vector<dgl::runtime::NDArray, std::allocator<dgl::runtime::NDArray> >)+0xcd3) [0x2b048e5e0b73]\n  [bt] (5) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::SpMM(std::string const&, std::string const&, std::shared_ptr<dgl::BaseHeteroGraph>, dgl::runtime::NDArray, dgl::runtime::NDArray, dgl::runtime::NDArray, std::vector<dgl::runtime::NDArray, std::allocator<dgl::runtime::NDArray> >)+0x244e) [0x2b048e61540e]\n  [bt] (6) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(+0x66cd50) [0x2b048e634d50]\n  [bt] (7) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(+0x66d361) [0x2b048e635361]\n  [bt] (8) /home/tysinger/.conda/envs/txgnn_env2/lib/python3.8/site-packages/dgl/libdgl.so(DGLFuncCall+0x48) [0x2b048e688138]\n\n"
     ]
    }
   ],
   "source": [
    "## here as a demo, the n_epoch is set to 30. Change it to n_epoch = 500 when you use it\n",
    "\n",
    "\n",
    "TxGNN_model.finetune(n_epoch = 15, \n",
    "               learning_rate = 5e-4,\n",
    "               train_print_per_n = 5,\n",
    "               valid_per_n = 50,\n",
    "               save_path = '/om/user/tysinger/models', \n",
    "                name = 'random_finetune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TxGNN_model.save_model('./model_noproto')\n",
    "#TxGNN_model.load_pretrained('./model_noproto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TxGNN_model.train_graphmask(relation = None, #changed from 'indication'\n",
    "                      learning_rate = 3e-4,\n",
    "                      allowance = 0.005,\n",
    "                      epochs_per_layer = 1,\n",
    "                      penalty_scaling = 1,\n",
    "                      valid_per_n = 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = TxGNN_model.retrieve_save_gates('./model_noproto')\n",
    "TxGNN_model.save_graphmask_model('./graphmask_model_noproto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from txgnn import TxEval\n",
    "TxEval_model = TxEval(model = TxGNN_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate individual diseases\n",
    "#result = TxEval_model.eval_disease_centric(disease_idxs = [12661.0, 11318.0], \n",
    "                                     #relation = 'indication', \n",
    "                                     #save_result = False)\n",
    "\n",
    "# evaluate the entire test set\n",
    "result = TxEval_model.eval_molfunc_centric(molfunc_idxs = 'test_set', \n",
    "                                     show_plot = True, \n",
    "                                     verbose = True, \n",
    "                                     save_result = False,\n",
    "                                     return_raw = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TxEval_model.retrieve_disease_idxs_test_set('indication')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
